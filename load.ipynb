{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregamento e preparação de *datasets*\n",
    "\n",
    "O carregamento e preparação de *datasets* é um ótimo exercício para tomarmos conhecimento das ferramentas a serem utilizadas para o processamento de sinais em `python`, seja sinais biológicos quanto de outra natureza, como um som, corrente elétrica, etc.\n",
    "\n",
    "Nesta `notebook` será apresentado o carregamento de um *dataset* público do *website* `UCI - Machine Learning Repository`. O *dataset* a ser utilizado é o `EEG Database Data Set` (https://archive.ics.uci.edu/ml/datasets/EEG+Database).\n",
    "\n",
    "\n",
    "## Descrição do *dataset*:\n",
    "\n",
    "A intenção deste *dataset* é examinar por meio de algoritmos de inteligência computacional a pré-disposição genética que um paciente possui ao alcoolismo.\n",
    "\n",
    "Os principais dados analizados são do tipo *time-series*, em outras palavras, conjuntos de dados que representam um sinal mensurado no domínio do tempo. Os dados são completados com outros atributos como o nome do eletrodo, o número da amostra, etc. Outras informações relevantes do *dataset*:\n",
    "\n",
    "- Quantidade de atributos: 4\n",
    "- Número de instancias: 122\n",
    "- Existem dados faltantes? Sim\n",
    "- Tipos de dados encontrados: categórico, inteiro e real\n",
    "\n",
    "Existem três categorias de dados neste *dataset*:\n",
    "\n",
    "1. Small Data Set: <font color='red'>**descrever**</font>\n",
    "2. Large Data Set: <font color='red'>**descrever**</font>\n",
    "3. Full Data Set: <font color='red'>**descrever**</font>\n",
    "\n",
    "Cada sessão (*trial*) é armazenada da seguinte forma:\n",
    "\n",
    "```\n",
    "# co2a0000364.rd \n",
    "# 120 trials, 64 chans, 416 samples 368 post_stim samples \n",
    "# 3.906000 msecs uV \n",
    "# S1 obj , trial 0 \n",
    "# FP1 chan 0 \n",
    "0 FP1 0 -8.921 \n",
    "0 FP1 1 -8.433 \n",
    "0 FP1 2 -2.574 \n",
    "0 FP1 3 5.239 \n",
    "0 FP1 4 11.587 \n",
    "0 FP1 5 14.028\n",
    "...\n",
    "```\n",
    "\n",
    "As primeiras 4 linhas são de cabeçalho:\n",
    "\n",
    "**linha 1**: identificação do paciente e se ele indica um alcoólatra (a) ou controle (c) pela quarta letra (co2**a**0000364);\n",
    "\n",
    "**linha 4**: determina se o paciente foi exposto a um único estímulo (`S1 obj`), a dois estímulos iguais (`S2 match`) ou a dois estímulos diferentes (`S2 no match`);\n",
    "\n",
    "**linha 5**: identifica o início da coleta dos dados pelo eletrodo FP1. As 4 colunas são:\n",
    "\n",
    "```\n",
    "número_da_sessão identificação_do_eletrodo número_da_amostra valor_em_micro_volts\n",
    "```\n",
    "\n",
    "\n",
    "### Realizando o download \n",
    "\n",
    "Primeiro faremos um código para verificar se o *dataset* já foi baixado, caso contrário, executar o código de download:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baixando: smni_eeg_data.tar.gz ...\n",
      "Baixando: SMNI_CMI_TRAIN.tar.gz ...\n",
      "Baixando: SMNI_CMI_TEST.tar.gz ...\n",
      "Baixando: eeg_full.tar ...\n",
      "Downlod dos datasets concluído!\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen, urlretrieve\n",
    "import os\n",
    "\n",
    "\n",
    "urls = {\n",
    "    'small': 'https://archive.ics.uci.edu/ml/machine-learning-databases/eeg-mld/smni_eeg_data.tar.gz',\n",
    "    'large_train': 'https://archive.ics.uci.edu/ml/machine-learning-databases/eeg-mld/SMNI_CMI_TRAIN.tar.gz',\n",
    "    'large_test': 'https://archive.ics.uci.edu/ml/machine-learning-databases/eeg-mld/SMNI_CMI_TEST.tar.gz',\n",
    "    'full': 'https://archive.ics.uci.edu/ml/machine-learning-databases/eeg-mld/eeg_full.tar'\n",
    "}\n",
    "\n",
    "# verifica se o diretório dos datasets existe\n",
    "if not os.path.exists('dataset/'):\n",
    "    os.mkdir('dataset/')\n",
    "    for k, v in urls.items():\n",
    "        fn = v.split('/')[-1]\n",
    "        print('Baixando:', fn, '...')\n",
    "        urlretrieve(v, './dataset/{}'.format(fn))\n",
    "    print('Downlod dos datasets concluído!')\n",
    "else:\n",
    "    print('Dataset já baixado!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descompactando pastas e subpastas\n",
    "\n",
    "Agora é necessário descompactar (recursivamente) diversas pastas e subpastas em arquivos GZip. Algumas pastas estão com o arquivo na extensão `.tar`, já outras, `.tar.gz`. Não obstante, algumas subpastas estão compactadas e outras não."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descompactações finalizadas!\n"
     ]
    }
   ],
   "source": [
    "from subprocess import getoutput as gop\n",
    "import glob\n",
    "\n",
    "\n",
    "# único arquivo somente empacotado (tar)\n",
    "os.mkdir('dataset/eeg_full/')\n",
    "gop('tar -xvf dataset/eeg_full.tar -C dataset/eeg_full')\n",
    "os.remove('dataset/eeg_full.tar')\n",
    "\n",
    "while glob.glob('dataset/**/*.gz', recursive=True):\n",
    "    # quando o arquivo está empacotado (tar) e compactado (gz)\n",
    "    for f in glob.iglob('dataset/**/*.tar.gz', recursive=True):\n",
    "        gop('tar -zxvf {} -C {}'.format(f, f[:f.rindex('/')]))\n",
    "        os.remove(f)\n",
    "    # quando o arquivo está somente compactado (gz)\n",
    "    for f in glob.iglob('dataset/**/*.gz', recursive=True):\n",
    "        gop('gzip -d {}'.format(f))\n",
    "print('Descompactações finalizadas!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregando parte do dataset\n",
    "\n",
    "Vamos agora carregar o subconjunto \"small\" do *dataset* e fica como <font color='red'>**tarefa de casa**</font> carregar e preparar todos os outros subconjuntos..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 24\n",
      "drwxrwxr-x 124 rhubner rhubner 4096 mar 19 03:24 full\n",
      "drwxrwxr-x   4 rhubner rhubner 4096 mar 19 13:16 large\n",
      "drwxr-xr-x   8 rhubner rhubner 4096 mar 19 03:24 small\n"
     ]
    }
   ],
   "source": [
    "# organizando melhor as pastas\n",
    "os.rename('dataset/smni_eeg_data', 'dataset/small')\n",
    "os.rename('dataset/eeg_full', 'dataset/full')\n",
    "os.mkdir('dataset/large')\n",
    "os.rename('dataset/SMNI_CMI_TRAIN/', 'dataset/large/SMNI_CMI_TRAIN/')\n",
    "os.rename('dataset/SMNI_CMI_TEST/', 'dataset/large/SMNI_CMI_TEST/')\n",
    "print(gop('ls -l dataset/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identificando pastas\n",
    "folders = {\n",
    "    'small': 'dataset/small/',\n",
    "    'large': 'dataset/large/',\n",
    "    'full': 'dataset/full/',\n",
    "}\n",
    "# carregando pasta \"small\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
